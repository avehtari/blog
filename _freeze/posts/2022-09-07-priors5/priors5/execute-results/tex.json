{
  "hash": "ca78aefcbc23ed2f3527be006080a447",
  "result": {
    "markdown": "---\ntitle: \"Priors for the parameters in a Gaussian process\"\n\nformat:\n  pdf:\n    toc: true\n    number-sections: true\n---\n\n\n\nLong time readers will know that I bloody love a Gaussian process. I wrote an _extremely detailed_ post on the [various ways to define Gaussian processes](https://dansblog.netlify.app/posts/2021-11-03-yes-but-what-is-a-gaussian-process-or-once-twice-three-times-a-definition-or-a-descent-into-madness/yes-but-what-is-a-gaussian-process-or-once-twice-three-times-a-definition-or-a-descent-into-madness.html). And I did not do that because I just love inflicting Hilbert spaces on people. In fact, the only reason that I ever went beyond the standard operational definition of GPs that most people live their whole lives using is that I needed to. \n\nTwice. \n\nThe first time was when I needed to understand approximation properties of a certain class of GPs. [I wrote a post about it](https://dansblog.netlify.app/posts/2021-11-24-getting-into-the-subspace/getting-into-the-subspace.html). It's intense^[The most common feedback was \"I hung in for as long as I could\".].\n\nThe second time that I really needed to dive into their arcana and apocrypha^[If you don't think we're gonna get our Maccabees on you're dreamin'. Hell, I might have to post Enoch-ussy on main.] was when I foolishly asked the question _can we compute PC priors for Gaussian processes?_.\n\nThe answer was yes. But it's a bit tricky.\n\nSo today I'm going to walk you through the ideas. There's no real need to read the GP post before this one^[you might just need to trust me at some points], but it would be immensely useful to have at least glanced at the [post on PC priors](https://dansblog.netlify.app/posts/2022-08-29-priors4/priors4.html).\n\n## What are we trying to do?\n\nWe are in the situation where we have a model that looks something like this^[It could be easily more complex with multilevel component, multiple GPs, time series components etc etc. But the simplest example is a GP regression.] ^[The GP has mean zero for the same reason we usually centre our covariates: it lets the intercept model the overall mean.]\n\\begin{align*}\ny_i \\mid \\beta, u, \\theta &\\sim p(y_i \\sim \\beta, u, \\phi) \\\\\nu(\\cdot) \\mid \\theta &\\sim GP(0, c_\\theta) \\\\\n\\beta, \\phi &\\sim p(\\beta,\\phi),\n\\end{align*}\nwhere $c_\\theta(\\cdot,\\cdot)$ is a covariance function with parameters $\\theta$ and we need to specify a joint prior on the GP parameters $\\theta$.\n\nThe simplest case of this would be GP regression, but a key thing here is that, in general, the structure (or functional form) of the priors on $\\theta$ probably shouldn't be too tightly tied to the tied to the specific likelihood. Why do I say that? Well the _scaling_ of a GP should depend on information about the likelihood, but it's hard to make a compelling case for the other type of information conveyed by a prior to depend on it.\n\nNow this view is predicated on us wanting to make an informative prior. In some very special cases, people with too much time on their hands have derived reference priors for specific models involving GPs.  These priors care _deeply_ about which likelihood you use. In fact, if you use them with a different model^[Not just the likelihood but also everything else in the model], you may not end up with a proper^[A challenge with reference priors is that they are often improper (aka they don't integrate to 1). This causes some conceptual difficulties, but there is a whole theory of Bayes that's mostly fine with this as long as the resulting posterior integrates to one. But this is by no means guaranteed and is typically only checked in very specific cases.  Jim Berger, one of the bigger proponents of reference prior, used to bring his wife to conference poster sessions. When she got bored, she would simply find a grad student and ask them if they'd checked if the posterior was proper. Sometimes you need to make your own fun.] posterior.We will talk about those later.\n\nTo start, let's look at the simplest way to build a PC prior. We will then talk about why this is not a good idea.\n\n### A first crack at a PC prior\n\nAs always, the best place to start is the simplest possible option. There's always a hope^[Hope has no place in statistics.] that we won't need to pull out the big guns. \n\nSo what is the simplest solution? Well it's to treat a GP as just a specific multivariate Gaussian distribution \n$$\nu \\sim GP(0, \\sigma^2R(\\theta)),\n$$\nwhere $R(\\theta)$ is a correlation matrix.\n\nThe nice thing about a multivariate Gaussian is that we have a clean expression for its Kullback-Leibler divergence. Wikipedia tells us that for an $n$-dimensional multivariate Gaussian\n$$\n2\\operatorname{KL}(N(0, \\Sigma) || N(0, \\Sigma_0)) = \\operatorname{tr}\\left(\\Sigma_0^{-1}\\Sigma\\right) + \\log \\det \\Sigma_0 - \\log \\det \\Sigma- n.\n$$\nTo build a PC prior we need to consider a base model. That's tricky in generality, but as we've assumed that the covariance matrix can be decomposed into the variance $\\sigma^2$ and a correlation matrix $R(\\theta)$, we can at least specify an easy base model for $\\sigma$. As always, the simplest model is one with no GP in it, which corresponds to $\\sigma_\\text{base} = 0$. From here, we can follow the usual steps to specify the PC prior \n$$\np(\\sigma) = \\lambda e^{-\\lambda \\sigma},\n$$\nwhere we choose $\\lambda = \\log(\\alpha)/U$ for some upper bound $U>0$ and some tail probaility $0<\\alpha<1$ so that \n$$\n\\Pr(\\theta > U) = \\alpha.\n$$\nThe specific choice of $U$ will depend on the context. For instance, if it's logistic regression we probably want something like^[Remember that any number on the logit scale outside of $[-3,3]$ might as well be the same number] $U=1$. If we have a GP on the log-mean of a Poisson distribution, then we probably want $U < 21.5$ if you want the _mean_ of the Poisson distribution to be less than the maximum integer^[`log(.Machine$integer.max) = 21.48756`] in R. In most data, you're gonna want^[$e^5 \\approx 148$, so 70% of the prior mass is less than that. 90% of the prior mass is less than $e^{10} \\approx 22026$ and 99% is less than $10^{13}$. This is still a weak prior.] $U\\ll 5$. If the GP is on the mean of a normal distribution, the choice of $U$ will depend on the context and scaling of the data.\n\nWithout more assumptions about the form of the covariance function, it is impossible to choose a base model for the other parameters $\\theta$.\n\nThat said, there is one special case that's important: the case where $\\sigma = \\ell$ is a single parameter controlling the intrinsic length scale, that is the distance at which the correlation between two points $\\ell$ units apart is approximately zero. The larger $\\ell$ is, the more correlated observations of the GP are and, hence, the less wiggly its realisation is. On the other hand, as $\\ell \\rightarrow 0$, the observations GP often behaves like realisations from an iid Gaussian and the GP becomes^[Conceptually. The mathematics of what happens as $\\ell \\rightarrow 0$ aren't really worth focusing on.] wilder and wilder.\n\nThis suggests that a good base model for the length-scale parameter would be $\\ell = \\infty$. We note that if both the base model and the alternative have the same value of $\\sigma$, then it cancels out in the KL-divergence. Under this assumption, we get that\n$$\nd(\\ell \\mid \\sigma) = \\text{``}\\lim_{\\ell_0\\rightarrow \\infty}\\text{''} \\sqrt{\\operatorname{tr}\\left(R(\\ell_0)^{-1}R(\\ell)\\right)  - \\log \\det R(\\ell) + \\log \\det R(\\ell_0) - n},\n$$\nwhere I'm being a bit cheeky putting that limit in, as we might need to do some singular model jigery-pokery of the same type we needed to do [for the standard deviation](https://dansblog.netlify.app/posts/2022-08-29-priors4/priors4.html#the-speed-of-a-battered-sav-proximity-to-the-base-model). We will formalise^[It's going to turn out that we don't have to do anything weird, but I don't want to discount the posibility.] this, I promise.\n\nAs the model gets more complex as the length scale decreases, we want our prior to control the smallest value $\\ell$ can take. This suggests we want to choose $\\lambda$ to ensure \n$$\n\\Pr(\\ell < L) = \\alpha.\n$$\nHow do we choose the lower bound $L$? One idea is that our prior should have very little probability of the length scale being smaller than the length-scale of the data. So we can chose $L$ to be the smallest distance between observations (if the data is regularly spaced) or as a low quantile of the distribution of distances between nearest neighbours. \n\nAll of this will specify a PC prior for a Gaussian process. So let's now discuss why that prior is a bit shit.\n\n### What's bad about this?\n\nThe prior on the standard deviation is fine.\n\nThe prior on the length scale is more of an issue. There are a couple of bad things about this prior. The first one might seem innocuous at first glance. We decided to treat the GP as a multivariate Gaussian with covariance matrix $\\sigma^2 R(\\theta)$.\nThis is not a neutral choice. In order to do it, we need to _commit_ to a certain set of observation locations^[Or, you know, linear functionals]. Why? The matrix $R(\\theta)$ depends entirely on the observation locations and if we use this matrix to define the prior we are tied to those locations. \n\nThis means that if we change the amount of data in the model we will need to change the prior. This is going to play havoc^[You can find Bayesians who say that they don't care if cross validation works or not. You can find Bayesians who will say just about anything.] on any sort of cross-validation! It's worth saying that the other two sources of information (the minimum length scale and the upper bound on $\\sigma$) are not nearly as sensitive to small changes in the data. This information is, in some sense, fundamental to the problem at hand and, therefore, much more stable ground to build your prior upon.\n\nThere's another problem, of course: this prior is expensive to compute. The KL divergence involves computing $\\operatorname{tr}(R(\\ell_0)^{-1}R(\\ell))$ which costs as much as another log-density evaluation for the Gaussian process (which is to say it's very expensive).\n\nSo this prior is going to be _deeply_ inconvenient if we have varying amounts of data (through cross-validation or sequential data gathering). It's also going to be wildly more computationally expensive than you expect a one-dimensional prior to be.\n\nAll in all, it seems a bit shit.\n\n### The Matérn covariance fucntion\n\nIt won't be possible to derive a prior for a general Gaussian process, so we are going to need to make some simplifying assumptions. The assumption that we are going to make is that the \ncovariance comes from the Whittle-Matérn^[There are lots of parameterisations, but they're all easy to move between. Compared to wikipedia, we use the $\\sqrt{8}$ scaling rather than the $\\sqrt{2}$ scaling.] ^[Everything in this post can be easily generalised to having different length scales on each dimension.] class \n$$\nc(s, s') = \\sigma^2 \\frac{2^{1-\\nu}}{\\Gamma(\\nu)}\\left(\\sqrt{8\\nu}\\frac{\\|s-s'\\|}{\\ell}\\right)^\\nu K_\\nu\\left(\\sqrt{8\\nu}\\frac{\\|s-s'\\|}{\\ell}\\right),\n$$\nwhere $\\nu$ is the _smoothness_ parameter, $\\ell$ is the _length-scale_ parameter, $\\sigma$ is the _marginal standard deviation_, and \n$$\nK_\\nu(x) = \\int_0^\\infty e^{-x\\cosh t}\\cosh(\\nu t)\\,dt\n$$\nis the modified Bessel^[If you've not run into these before, $x^{\\nu}K_\\nu(x)$ is [finite at zero](https://functions.wolfram.com/Bessel-TypeFunctions/BesselK/06/01/04/01/03/) and decreases monotonically in an exponential-ish fashion as $x\\rightarrow \\infty$.] function of the second kind.\n\nThis class of covariance function is extremely important in practice. It interpolates between two of the most common covariance functions: \n\n- when $\\nu = 1/2$, it corresponds to the exponential covariance function,\n- when $\\nu = \\infty$, it corresponds to the square exponential covariance.\n\nThere are years of experience suggesting that Matérn covariance functions with finite $\\nu$ perform better than the square exponential covariance.\n\nCommon practice is to fix^[Possibly trying several values and either selecting the best or stacking all of the models] the value of $\\nu$. There are a few reasons for this. One of the most compelling practical reasons is that we can't easily evaluate its derivative, which rules out most modern optimisation and MCMC algorithms. It's also _very_ difficult to think about how you would set a prior on it. The techniques in this post will not help, and as far as I've ever been able to tell, nothing else will either.  Finally, you could expect there to be _horrible_ confounding between $\\nu$, $\\ell$, and $\\sigma$, which will make inference very hard (both numerically and morally).\n\nIt turns out that even with $\\nu$ fixed, we will run into a few problems. But to understand those, we are going to need to know a bit more about how inferring parameters in a Gaussian processes actually works.\n\n\n### Asymptotics? I barely know her!\n\nLet's take a brief detour into classical inference for a moment and ask ourselves\n_when can we recover the parameters of a Gaussian process_? For most models we \nrun into in statistics, the answer to that question is _when we get enough data_.\nBut for Gaussian processes, the story is more complex.\n\nFirst of all, there is the very real question of what we mean by getting more data.\nWhen our observations are iid, this so easy that when asked how she got more data, Kylie just said she [\"did it again\"](https://www.youtube.com/watch?v=jDKPvy-ZXC8).\n\nBut this is more complex once data has dependence. For instance, in a multilevel \nmodel you could have the number of groups staying fixed while the number of observations in each group goes to infinity, you could have the number of observations in each group staying fixed while the number of groups go to infinity, or you could have both^[At which point you need to ask yourself if one goes their faster. It's chaos.] going to infinity.\n\nFor Gaussian processes it also gets quite complicated. Here is a non-exhaustive list of options:\n\n- You observe the same realisation of the GP at an increasing number of points that eventually cover the _whole of_ $\\mathbb{R}^d$ (this is called the _increasing domain_ or _outfill_ regime); or\n- You observe the same realisation of the GP at an increasing number of points _that stay within a fixed domain_ (this is called the _fixed domain_ or _infill_ regime); or\n- You observe multiple realisations of the same GP at a finite number of points that stay in the same location (this does not have a name); or\n- You observe multiple realisations of the same GP at a (possibly different) finite number of points that can be in different locations for different realisations; or\n- You observe realisations of a process that evolves in space _and_ time (not really a different regime so much as a different problem).\n\nOne of the truly unsettling things about Gaussian processes is that the ability to estimate the parameters depends on which of these regimes you choose!\n\nOf course, we all know that asymptotic regimes are just polite fantasies that statisticians concoct in order to self-soothe. They are not reflections on reality. They serve approximately the same purpose^[Asymptotics as copaganda.] as watching a chain of Law and Order episodes.\n\nThe real purpose of thinking about what happens when we get more data is to use it as a loose approximation of what happens with the data you have. So the real question is _which regime is the most realistic for my data_?. \n\nOne way you can approach this question is to ask yourself what you would do if you\nhad the budget to get more data. My work has mostly been in spatial statistics, in which case the answer is _usually_ that you would sample more points in the same area. This suggests that fixed-domain asymptotics is a good fit for my needs. I'd expect that\nin most GP regression cases, we're not expecting^[or hoping] that further observations would be on new parts of the covariate space, which would suggest fixed-domain asymptotics are usefulthere too.\n\nThis, it turns out, is awkward.\n\n### When is a parameter not consistently estimatable: an aside that will almost immediately become relevant\n\nThe problem with a GP with the Matérn covariance function on a fixed domain is\nthat it's not possible^[in 3 or fewer dimensions] to estimate all of its parameters at the same time. This isn't the case for the other \nasymptotic regime, but you've got to dance with who you came to the dance with.\n\nTo make this more concrete, we need to think about a Gaussian process as a realisation of a function rather than as a vector of observations. Why? Because under fixed-domain asymptotics we are seeing values of the function closer and cloer together until we essentailly see the entire function on that domain.\n\nOf course, this is why I wrote [a long and technical blog post](https://dansblog.netlify.app/posts/2021-11-03-yes-but-what-is-a-gaussian-process-or-once-twice-three-times-a-definition-or-a-descent-into-madness/yes-but-what-is-a-gaussian-process-or-once-twice-three-times-a-definition-or-a-descent-into-madness.html) on understanding Gaussian processes as random functions. But don't worry. You don't need to have read that part.\n\nThe key thing is that because a GP is a function, we need to think of it's probability of being in a set $A$ of functions. There will be a set of function $\\operatorname{supp}(u)$, which we call the _support_ of $u(\\cdot)$ that is the smallest set such that \n$$\n\\Pr(u(\\cdot) \\in \\operatorname{supp}(u)) = 1.\n$$\nEvery GP has an associated support and, while you probably don't think much about it, GPs are _obsessed_ with their supports. They love them. They hug them. They share them with their friends. They keep them from their enemies. And they are one of the key things that we need to think about in order to understand why it's hard to estimate parameters in a Matérn covariance function.\n\nThere is a key theorem that is unique^[I have not fact checked this] to Gaussian processes.\nIt's usually phrased in terms of _Gaussian measures_, which are just the probability associated with a GP. For example, if $u_1(\\cdot)$ is a GP then\n$$\n\\mu_1(A) = \\Pr(u_1(\\cdot) \\in A)\n$$\nis the corresponding Gaussian measure. We can express the support of $u(\\cdot)$ as the smallest set of functions such that $\\mu(A)=1$.\n\n\n::: {#thm-singular-equiv}\n\n## Feldman-Hájek theorem\n\nTwo Gaussian measures $\\mu_1$ and $\\mu_2$ with corresponding GPs $u_1(\\cdot)$ and $u_2(\\cdot)$ on a locally convex space^[Basically everything you care about. Feel free to google the technical definition. But any space with a metric is locally convex. Lots of things that aren't metric spaces are too.] either satisfy, for every^[measurable] set $A$   \n$$\n\\mu_2(A) > 0 \\Rightarrow \\mu_1(A) > 0 \\text{ and } \\mu_1(A) > 0 \\Rightarrow \\mu_2(A) > 0,\n$$\nin which case we say that $\\mu_1$ and $\\mu_2$ are _equivalent_^[This will seem a bit weird if it's the first time you've seen the concept. In finite dimensions (aka most of statistics) _every_ Gaussian is equivalent to every other Gaussian. In fact, it's equivalent to every other continuous distribution with non-zero density on the whole of $\\mathbb{R}^d$. But shit gets weird when you're dealing with functions and we just need to take a hit of the video head cleaner and breathe until we get used to it.] (confusingly^[These measures _are not the same_. They just happen to be non-zero on the same sets.] written $\\mu_1 \\equiv \\mu_2$) and $\\operatorname{supp}(u_1) = \\operatorname{supp}(u_2)$, **or**\n$$\n\\mu_2(A) > 0 \\Rightarrow \\mu_1(A) = 0 \\text{ and } \\mu_1(A) > 0 \\Rightarrow \\mu_2(A) = 0,\n$$\nin which case we say $\\mu_1$ and $\\mu_2$ are _singular_ (written $\\mu_1 \\perp \\mu_2$) and $u_1(\\cdot)$ and $u_2(\\cdot)$ have disjoint supports.\n:::\n\nLater on in the post, we will see some precise conditions for when two Gaussian measures are equivalent, but for now it's worth saying that it is a _very_ delicate property. In fact, if $u_2(\\cdot) = \\alpha u_1(\\cdot)$ for any $|\\alpha|\\neq 1$, then $\\mu_1 \\perp \\mu_2$!\n\nThis seems like it will cause problems. And it can^[eg, computationally where Metropolis-Hastings acceptance probabilities have an annoying tendency to go to zero unless you are extraordinarily careful.]. But it's _fabulous_ for inference.\n\nTo see this, we can use one of the implications of singularity: $\\mu_1 \\perp \\mu_2$\nif and only if\n$$\n\\operatorname{KL}(u_1(\\cdot) || u_2(\\cdot)) = \\infty,\n$$\nwhere the the Kullback-Leibler divergence can be interpreted as the expectation of the likelihood ratio of $u_1$ vs $u_2$ under $u_1$. Hence, if $u_1(\\cdot)$ and $u_2(\\cdot)$ are singular, we can (on average) choose the correct one using a likelihood ratio test. This means that we will be able to correctly recover the true^[if it exists] parameter.\n\nIt turns out the opposite is also true. \n\n::: {#thm-strong-neg}\n\nIf $\\mu_\\theta$, $\\theta \\in \\Theta$ is a family of Gaussian measures corresponding to the GPs $u_\\theta(\\cdot)$ and $\\mu_\\theta \\equiv \\mu_{\\theta'}$ for all values of $\\theta, \\theta' \\in \\Theta$, then there is _no_ sequence of estimators $\\hat \\theta_n$ such that, for all $\\theta_0 \\in \\Theta$ \n$$\n{\\Pr}_{\\theta_0}(\\hat \\theta_n \\rightarrow \\theta_0) = 1,\n$$\nwhere ${\\Pr}_{\\theta_0}(\\cdot)$ is the probability under data drawn with true parameter $\\theta_0$. That is there is no estimator $\\hat \\theta_n$ that is (strongly) consistent for all $\\theta \\in \\Theta$.\n:::\n\n<details><summary>Click for a surprise (the proof. shit i spoiled the surprise)</summary>\n::: {.proof}\n\nWe are going to do this by contradiction. So assume that there is a sequence such that \n$$\n\\Pr{_{\\theta_0}}(\\hat \\theta_n \\rightarrow \\theta_0) = 1.\n$$\nFor some $\\epsilon >0$, let $A_n = \\{\\|\\hat\\theta_n - \\theta_0\\|>\\epsilon\\}$. Then we can re-state our almost sure convergence as \n$$\n\\Pr{_{\\theta_0}}\\left(\\limsup_{n\\rightarrow \\infty}A_n\\right) = 0,\n$$\nwhere the limit superior is defined^[This can be interpreted as the event that $|\\hat\\theta_n - \\theta_0| > 0$ infinity many times which would strongly suggest that it's not bloody converging.] as \n$$\n\\limsup_{n\\rightarrow \\infty}A_n = \\bigcap_{n=1}^\\infty \\left(\\bigcup_{m=n}^\\infty A_n\\right).\n$$\n\nFor any $\\theta' \\neq \\theta_0$ with $\\mu_{\\theta'} \\equiv \\mu_{\\theta_0}$, the definition of equivalent measures tells us that\n$$\n\\Pr{_{\\theta'}}\\left(\\limsup_{n\\rightarrow \\infty}A_n\\right) = 0\n$$\nand therefore \n$$\n\\Pr{_{\\theta'}}\\left(\\hat \\theta_n \\rightarrow \\theta_0\\right) = 1.\n$$\nThe problem with this is that is that this data is generated using $u_{\\theta'}$, but the estimator converges to $\\theta_0$ instead of $\\theta'$. Hence, the estimator isn't uniformly (strongly) consistent.\n:::\n</details>\n\n\n\nThis seems bad but, you know, it's a pretty strong version of convergence. And sometimes our brothers and sisters in Christ who are more theoretically minded like to give themselves a treat and consider weaker forms of convergence. It turns out that that's a disaster too.\n\n::: {#thm-weak-neg}\n\nIf $\\mu_\\theta$, $\\theta \\in \\Theta$ is a family of Gaussian measures corresponding to the GPs $u_\\theta(\\cdot)$ and $\\mu_\\theta \\equiv \\mu_{\\theta'}$ for all values of $\\theta, \\theta' \\in \\Theta$, then there is _no_ sequence of estimators $\\hat \\theta_n$ such that, for all $\\theta_0 \\in \\Theta$ and all $\\epsilon > 0$\n$$\n\\lim_{n\\rightarrow \\infty}{\\Pr}_{\\theta_0}(\\|\\hat \\theta_n - \\theta_0\\| > \\epsilon) = 0.\n$$\n That is there is no estimator $\\hat \\theta_n$ that is (weakly) consistent for all $\\theta \\in \\Theta$.\n:::\n\nIf you can't tell the difference between these two theorems that's ok. You probably weren't trying to sublimate some childhood trauma and all of your sexual energy into maths just so you didn't have to deal with the fact that you might be gay and you were pretty sure that wasn't an option and anyway it's not like it's _that_ important. Like whatever, you don't need physical or emotional intimacy. You've got a pile of books on measure theory next to your bed. You are living your best life. Anyway. It makes almost no practical difference. BUT I WILL PROVE IT ANYWAY.\n\n<details><summary>Once more, into the proof.</summary>\n::: {.proof}\nThis proof is based on a kinda advanced fact, which involves every mathematician's favourite question: what happens along a subsequence?\n\n::: {.callout-note icon=false}\n\n## Probability Fact!\n\nIf $\\hat \\theta_n$ converges to $\\theta$ in probability, then there exists an infinite sub-sequence $\\hat \\theta_{n_k}$, where $n_k \\rightarrow \\infty$ as $k \\rightarrow \\infty$, such that $\\hat \\theta_{n_k}$ converges to $\\theta$ with probability one (or almost surely).\n:::\n\nThis basically says that the two modes of convergence are quite similar except convergence in probability is relaxed enough to have some^[or even many] values that aren't doing so good at the whole converging thing.\n\nWith this in hand, let us build a contradiction. Assume that $\\hat \\theta_n$ is weakly consistent for all $\\theta \\in \\Theta$. Then, if we generate data under $\\mu_{\\theta_0}$, then we get that, along a subsequence $n_k$\n$$\n\\Pr{_{\\theta_0}}(\\hat \\theta_{n_k} \\rightarrow \\theta_0) =1.\n$$\n\nNow, if $\\hat \\theta_n$ is weakly consistent for all $\\theta$, then so is $\\hat \\theta_{n_k}$. Then, by our assumption, for every $\\theta' \\in \\Theta$ and every $\\epsilon>0$ \n$$\n\\lim_{k \\rightarrow \\infty} \\Pr{_{\\theta'}}\\left(\\|\\hat \\theta_{n_k} - \\theta'\\| > \\epsilon\\right) = 0.\n$$\n\nOur probability fact tells us that there is a _further_ infinite sub-sub-sequence $n_{k_\\ell}$ such that \n$$\n\\Pr{_{\\theta'}}\\left(\\hat \\theta_{n_{k_\\ell}} \\rightarrow \\theta'\\right) = 1.\n$$\nBut @thm-strong-neg tells us that $\\hat \\theta_{n_k}$ (and hence $\\theta_{n_{k_l}}$) satisfies\n$$\n\\Pr{_{\\theta'}}\\left(\\hat \\theta_{n_{k_\\ell}} \\rightarrow \\theta_0\\right) = 1.\n$$\nThis is a contradiction unless $\\theta'= \\theta_0$, which proves the assertion.\n\n:::\n</details>\n\n\n### Matérn fields under fixed domain asymptotics: the love that dares not speak its name\n\nAll of that lead up immediately becomes extremely relevant once we learn one thing about Gaussian processes with the Matérn covariance function. \n\n::: {#thm-matern-sing}\n\nLet $\\mu_{\\nu, \\sigma, \\ell}$ be the Gaussian measure corresponding to the GP with Matérn covariance function with parameters $(\\nu, \\sigma, \\ell)$, let $D$ be any finite domain in $\\mathbb{R}^d$, and let $d \\leq 3$. Then, restricted to $D$,\n$$\n\\mu_{\\nu,\\sigma_1, \\ell_1} \\equiv \\mu_{\\nu, \\sigma_2, \\ell_2}\n$$\nif and only if \n$$\n\\frac{\\sigma_1^2}{\\ell_1^{2\\nu}} = \\frac{\\sigma_2^2}{\\ell_2^{2\\nu}}.\n$$\n\n:::\n\nI'll go through the proof of this later, but the techniques require a lot of warm up, so let's just deal with the consequences for now.\n\nBasically, @thm-matern-sing says that we can't consistently estimate the range and the marginal standard deviation for a one, two, or three dimensional Gaussian process. [Hao Zhang noted this](https://www.stat.purdue.edu/~zhanghao/Paper/JASA2004.pdf) and that it remains true^[Technically, a recent paper in JRSSSB said that if you add an iid Gaussian process you will get identifiability, but that's maybe not the most realistic asymptotic approximation.] when dealing with non-Gaussian data.\n\nThe good news, I guess, is that in more than four^[The fourth dimension is where mathematicians go to die] dimensions the measures are always singular.\n\nNow, I don't give one single solitary shit about the existence of consistent estimators. I am doing Bayesian things and this post is supposed to be about setting prior distributions. But it is important.  Let's take a look at some simulations.\n\nFirst up, let's look at what happens in 2D when we directly (ie with no noise) observe a zero-mean GP with exponential covariance function ($\\nu = 1/2$) at points in the unit square.\nIn this case, the log-likelihood is, up to an additive constant,\n$$\n\\log p(y \\mid \\theta) = -\\frac{1}{2}\\log |\\Sigma(\\theta)| - \\frac{1}{2}y^T\\Sigma(\\theta)^{-1}y.\n$$\n\nThe R code is not pretty but I'm trying to be relatively efficient with my Cholesky factors.\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(30127)\nlibrary(tidyverse)\ncov_fun <- \\(h,sigma, ell) sigma^2 * exp(-h/ell)\n\nlog_lik <- function(sigma, ell, y, h) {\n  V <- cov_fun(h, sigma, ell)\n  R <- chol(V)\n  -sum(log(diag(R))) - 0.5*sum(y * backsolve(R, backsolve(R, y, transpose = TRUE)))\n}\n```\n:::\n\n\nWe can now simulate 500 data points on the unit square, compute their distances, and simulate from the GP.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 500\ndat <- tibble(s1 = runif(n), s2 = runif(n), \n              dist_mat = as.matrix(dist(cbind(s1,s2))),\n              y = MASS::mvrnorm(mu=rep(0,n), \n                      Sigma = cov_fun(dist_mat, 1.0, 0.2)))\n```\n:::\n\n\nWith all of this in hand, let's look at the likelihood surface along^[It's computationally pretty expensive to plot the whole likelihood surface, so I'm just doing it along lines] the line \n$$\n\\frac{\\sigma^2}{\\ell} = c\n$$\nfor various values of $c$. I'm using some `purrr` trickery^[`partial` freezes a few parameter values, and `possibly`  replaces any calls that return an error with an NA] here to deal with the fact that sometimes the cholesky factorisation will throw an error.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm <- 100\nf <- partial(log_lik, y = dat$y, h = dat$dist_mat)\n\npars <- \\(c) tibble(ell = seq(0.05,1, length.out = m),\n                    sigma = sqrt(c * ell), c = rep(c, m))\n\n ll <- map_df(3:8,pars) |>\n  mutate(contour = factor(c), \n         ll = map2_dbl(sigma, ell, \n                       possibly(f, otherwise = NA_real_)))\n\n\nll |> ggplot(aes(ell, ll, colour = contour)) + \n  geom_line() +\n  scale_color_brewer(palette = \"Set1\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](priors5_files/figure-pdf/unnamed-chunk-3-1.pdf){fig-pos='H'}\n:::\n:::\n\n\nWe can see the same thing in 2D (albeit at a lower resolution for computational reasons). I'm also not computing a bunch of values that I know will just be massively negative.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nf_trim <- \\(sigma, ell) ifelse(sigma^2 < 3*ell | sigma^2 > 8*ell,\n                               NA_real_, f(sigma, ell))\nm <- 50\nsurf <- expand_grid(ell = seq(0.05,1,length.out = m),\n                    sigma = seq(0.1, 4, length.out = m)) |>\n  mutate(ll =  map2_dbl(sigma, ell, \n                       possibly(f_trim, otherwise = NA_real_)))\n\nsurf |> filter(ll > 50) |>\n  ggplot(aes(ell, sigma, fill = ll)) + \n  geom_raster() +\n  scale_fill_viridis_c() +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](priors5_files/figure-pdf/unnamed-chunk-4-1.pdf){fig-pos='H'}\n:::\n:::\n\n\nClearly there is a ridge in the likelihood surface, which suggests that our posterior is going to be driven by the prior along that ridge.\n\nFor completeness, let's run the same experiment again when we have some known observation noise, that is $y_i \\sim N(u(s_i), 1)$.\nIn this case, the log-likelihood is\n$$\n\\log p(y\\mid \\sigma, \\ell) = -\\frac{1}{2} \\log \\det(\\Sigma(\\theta) + I) - \\frac{1}{2}y^{T}(\\Sigma(\\theta) + I)^{-1}y.\n$$\n\nLet us do the exact same thing again!\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 500\ndat <- tibble(s1 = runif(n), s2 = runif(n), \n              dist_mat = as.matrix(dist(cbind(s1,s2))),\n              mu = MASS::mvrnorm(mu=rep(0,n), \n                      Sigma = cov_fun(dist_mat, 1.0, 0.2)),\n              y = rnorm(n, mu, 1))\n\nlog_lik <- function(sigma, ell, y, h) {\n  V <- cov_fun(h, sigma, ell)\n  R <- chol(V + diag(dim(V)[1]))\n  -sum(log(diag(R))) - 0.5*sum(y * backsolve(R, backsolve(R, y, transpose = TRUE)))\n}\n\nm <- 100\nf <- partial(log_lik, y = dat$y, h = dat$dist_mat)\n\npars <- \\(c) tibble(ell = seq(0.05,1, length.out = m),\n                    sigma = sqrt(c * ell), c = rep(c, m))\n\n ll <- map_df(3:8,pars) |>\n  mutate(contour = factor(c), \n         ll = map2_dbl(sigma, ell, \n                       possibly(f, otherwise = NA_real_)))\n\n\nll |> ggplot(aes(ell, ll, colour = contour)) + \n  geom_line() +\n  scale_color_brewer(palette = \"Set1\") +\n  theme_bw()\n```\n\n::: {.cell-output-display}\n![](priors5_files/figure-pdf/unnamed-chunk-5-1.pdf){fig-pos='H'}\n:::\n:::\n\n\nOnce again, we can see that there is going to be a ridge in the likelihood surface! It's a bit less disastrous this time, but it's not excellent even with 500 observations (which is a decent number on a unit square). The weird structure of the prior is still going to lead to a long, non-elliptical shape in your posterior that your computational engine (and your person interpeting the results) are going to have to come to terms with. \n\nUnless, of course, the prior can save you.\n\n### So the prior is important then! What do other people do?\n\nThat ridge in the likelihood surface does not go away in low dimensions, which essentially means that our inference along that ridge is going to be driven by the prior.\n\nPossibly the worst choice you could make in this situation is trying to make a minimally informative prior. Of course, that's what [somebody did](https://www.google.com/search?client=safari&rls=en&q=Objective+Bayesian+Analysis+of+Spatially+Correlated+Data%2C&ie=UTF-8&oe=UTF-8). In fact it was the first paper^[That I could find] that looks rigorously at prior distributions on the parameters of GPs. It's just unfortunate that it's quite shit. It has still been cited quite a lot. And there are some technical advances to the theory of reference priors, but if you use it you just find yourself mapping out that damn ridge.\n\nOn top of being, structurally, a bad choice, the reference prior has a few other downsides:\n\n- It is very computationally intensive and quite complex. Not unlike the bad version of the PC prior!\n- It requires _strong_ assumptions about the likelihood. The first version assumed that there was no observation noise. Later papers allowed there to be observation noise. But only if it's Gaussian.\n- It is derived under the asymptotic regime where an infinite sequence of different independent realisations of the GP are observed at the same finite set of points. This is not the most useful regime for GPs.\n\nAll in all, it's a bit of a casserole. \n\nFrom the other end, there's a very interesting contribution from [Aad van der Vaart and Harry von Zanten](https://arxiv.org/pdf/0908.3556.pdf) wrote a very lovely theoretical paper that looked at which priors on $\\ell$ could result in theoretically optimal posterior contraction  rates. They argued that $\\ell^d$ should have a Gamma distribution. Within the Matérn class, their results are only valid for the squared exponential contrivance function.\n\nNeither of these papers consider that ridge in the likelihood surface.\n\nThis lack of consideration---as well as their success in everything else we tried them on---was a big part of our push to make a useful version of a PC prior for Gaussian processes.\n\n\n### Rescuing the PC prior; or What I recommend you do\n\nIt has been a long journey, but we are finally where I wanted us to be. So let's talk about how to fix the PC prior.\n\nIn order to solve this problem, we are going to do three things in the rest of this post:\n\n1. Restrict our attention to the stationary^[Saddle up for some spectral theory.] GPs \n1. Restrict our attention to the Matérn class of covariance functions. \n1. Greatly increase our mathematical^[I'm terribly sorry.] sophistication.\n\nBut before we do that, I'm going to walk you through the punchline.\n\nThis work was originally done with the magnificent [Geir-Arne Fuglstad](https://www.ntnu.edu/employees/fuglstad), the glorious [Finn Lindren](https://www.maths.ed.ac.uk/~flindgre/), and the resplendent [Håvard Rue](https://www.kaust.edu.sa/en/study/faculty/haavard-rue). If you want to read the original paper, [the preprint is here](https://arxiv.org/abs/1503.00256)^[I'm moderately sure that the preprint is pretty similar to the published version but I am not going to check.].\n\nThe short version is that the PC prior for the length scale in a $d$-dimensional space is a Fréchet distribution^[With this parameterisation it's sometimes known as a Type-II Gumbel distribution. Because why not.] with shape parameter $d/2$. That is, \n$$\np(\\ell) = \\frac{d\\lambda_\\ell}{2} \\ell^{-(d/2+1)}e^{-\\lambda_{\\ell}\\ell^{-d/2}},\n$$\nwhere we choose $\\lambda_\\ell = -\\log(\\alpha_\\ell)L^{d/2}$ to ensure that \n$$\n\\Pr(\\ell < L) = e^{-\\lambda L^{-d/2}} < \\alpha_\\ell.\n$$\nIn two dimensions, this is an inverse gamma prior, which gives rigorous justification to a commonly used prior in spatial statistics.\n\nThe remainder of this post will be devoted to justifying this choice. Maybe there will be some experiments at the end!\n\n\n\n## Stationary Gaussian processes\n\nGaussian processes with the Matérn covariance function are an excellent example of a stationary^[In fact, it's isotropic, which is a stricter condition on most spaces. But there's no real reason to specialise to isotropic processes so we simply won't.] Gaussian process, which are characterised^[We are assuming that the mean is zero, but absent that assumption, we need to assume that the mean is constant.] ^[For non-Gaussian processes, this property is known as _second-order_ stationarity. For GPs this corresponds to stong stationary, which is a property of the distribution rather than the covariance functio ] by have covariance functions of the form \n$$\nc(s, s') = c(s- s'),\n$$\nwhere I am abusing notation and using $c$ for both the two parameter and one parameter functions. This assumption means that the correlation structure does not depend on where you are in space, only on the distance between points.\n\nThe assumption of stationarity massively simplifies GPs. Firstly, the stationarity assumption greatly reduces the number of parameters you need to describe a GP as we don't need to worry about location-specific parameters. Secondly, it increases the statistical power of the model. If two subsets of the domain are more than $2\\ell$ apart, they are essentially independent replicates of the GP with the same parameters. This means that if the locations $s$ vary across a large enough area (relative to the natural length scale), we get multiple effective replicates^[If you've been exposed to the concept of ergodicity of random fields you may be eligible for compensation.] from the same realisation of the process.\n\nIn practice, stationarity^[Possibly with varying length scales or some other form of anisotropy] is often a _good enough_ assumption when the mean has been modelled carefully, [especially given the limitations of the data](https://arxiv.org/abs/1409.0743). That said, priors on non-stationary processes can be set using the PC prior methodology by using a stationary process as the base model. The [supplementary material](https://arxiv.org/abs/1503.00256) of our paper gives a simple, but useful, example of this.\n\n### Stationary covariance functions and Bochner's theorem\n\nThe restriction to stationary processes is _extremely_ powerful. It opens us up to using Fourier analysis as a potent tool for understanding GPs. We are going to need this to construct our KL divergence, and so with some trepidation, let's dive into the moonee ponds of spectral representations.\n\nThe first thing that we need to do is remember what a [_Fourier transform_] is. A Fourier transform of a square integrable function $\\phi(s)$ is^[This is normalisation is to make my life easier.] \n$$\n\\hat \\phi(\\omega) = \\mathcal{F}(\\phi)(\\omega) =\\frac{1}{(2\\pi)^d}\\int_{\\mathbb{R}^d} e^{-i\\omega^Ts}\\phi(s) \\,ds.\n$$\n\nIf you have bad memories^[Let's not lie, I just jumped straight to complex numbers. Some of you are having flashbacks.] of desperately trying to compute Fourier integrals in undergrad, I promise you that we are not doing that today. We are simply affirming their right to exist (and my right to look them up in a table).\n\nThe reason I care about Fourier^[Fourier-Stieljes] transforms is that if I have a non-negative measure^[countably additive set-valued function. Like a probability but it doesn't have to total to one] $\\nu$, I can define a function \n$$\nc(h) = \\int_{\\mathbb{R}^d}e^{i\\omega^Th}\\,d\\nu(\\omega).\n$$\nIf measures freak you out, you can---with some loss of generality---assume that there is a function $f(\\omega)\\geq 0$ such that \n$$\nc(h) = \\int_{\\mathbb{R}^d}e^{i\\omega^Th}f(\\omega)\\,d\\omega.\n$$\nWe are going to call $\\nu$ the spectral measure and the corresponding $f$, if it exists, is called the spectral density.\n\nI put it to you that, defined this way, $c(s,s') = c(s - s')$ is a (complex) positive definite function. \n\nRecall^[and complexify] that a function is positive definite if, for every for every $k>0$, every $s_1, \\ldots, s_k \\in \\mathbb{R}^d$, and every $a_1, \\ldots, a_k \\in \\mathbb{C}$\n$$\n\\sum_{i = 1}^k\\sum_{j=1}^k a_i\\bar{a}_j c(s_i, s_j) \\geq 0,\n$$\nwhere $\\bar a$ is the complex conjugate of $a$.\n\nUsing our assumption about $c(\\cdot)$ we can write the left hand side as \n\\begin{align*}\n\\sum_{i = 1}^k\\sum_{j=1}^k a_i\\bar{a}_j c(s_i, s_j) &= \\sum_{i = 1}^k\\sum_{j=1}^k a_i\\bar{a}_j c(s_i- s_j) \\\\\n&=\\sum_{i = 1}^k\\sum_{j=1}^k a_i\\bar{a}_j \\int_{\\mathbb{R}^d} e^{i\\omega^T(s_i-s_j}\\,d\\nu(\\omega) \\\\\n&=\\int_{\\mathbb{R}^d}\\sum_{i = 1}^k\\sum_{j=1}^k a_i\\bar{a}_j e^{i\\omega^T(s_i-s_j}\\,d\\nu(\\omega) \\\\\n&=\\int_{\\mathbb{R}^d}\\left(\\sum_{i = 1}^k a_i e^{i\\omega^Ts_i}\\right)\\left(\\sum_{j = 1}^k \\bar{a_j} e^{-i\\omega^Ts_j}\\right) \\,d\\nu(\\omega)\\\\\n&=\\int_{\\mathbb{R}^d}\\left(\\sum_{i = 1}^k a_i e^{i\\omega^Ts_i}\\right)\\overline{\\left(\\sum_{j = 1}^k a_j e^{i\\omega^Ts_j}\\right)} \\,d\\nu(\\omega) \\\\\n&=\\int_{\\mathbb{R}^d}\\left|\\sum_{i = 1}^k a_i e^{i\\omega^Ts_i}\\right|^2\\,d\\nu(\\omega) \\geq 0,\n\\end{align*}\nwhere $|a|^2 = a\\bar{a}$. \n\nWe have shown that if $c(s,s') = c(s-s') = \\int e^{i\\omega^T(s-s')}\\,d \\nu(\\omega)$ , then it is a valid covariance function. This is true, although harder to prove, in the other direction and the result is known as Bochner's theorem.\n\n::: {#thm-bochner}\n\n## Bochner's theorem\n\nA function $c(\\cdot)$ is positive definite, ie for every $k>0$, every $s_1, \\ldots, s_k \\in \\mathbb{R}^d$, and every $a_1, \\ldots, a_k \\in \\mathbb{C}$\n$$\n\\sum_{i = 1}^k\\sum_{j=1}^k a_i\\bar{a}_j c(s_i- s_j) \\geq 0,\n$$\nif and only if there is a non-negative finite measure $\\nu$ such that\n$$\nc(h) = \\int_{\\mathbb{R}^d} e^{i\\omega^Th}\\,d\\nu(\\omega).\n$$\n:::\n\nJust as a covariance function^[or a Cameron-Martin space] is enough to completely specify a zero-mean Gaussian process, a spectral measure is enough to completely specify a zero mean _stationary_ Gaussian process.\n\nOur lives are mathematically much easier when $\\nu$ represents a density $f(\\omega)$ that satisfies \n$$\n\\int_{\\mathbb{R}^d}\\phi(\\omega)\\,d\\nu(\\omega) = \\int_{\\mathbb{R}^d}\\phi(\\omega)f(\\omega)\\,d\\omega.\n$$\nThis function, when it exists, is precisely the Fourier transform of $c(h)$. Unfortunately, this will not exist^[That is, this measure bullshit isn't just me pretending to be smart. It's necessary.] for all possible positive definite functions. But as we drift further and further down this post, we will begin to assume that we're only dealing with cases where $f$ exists.\n\nThe case of particular interest to us is the Matérn covariance function, which has Fourier transform !!!!CHECK THIS!!!!!\n$$\nf(\\omega) = \\frac{\\Gamma(\\nu)}{\\Gamma(\\nu+d/2)(4\\pi)^{d/2}\\kappa^{2\\nu}\\sigma^2}\\frac{1}{(\\kappa^2 + \\|\\omega\\|^2)^{\\nu-d/2}}.\n$$\n\n### Spectral representations (and the simplest of the many many versions of a stochastic integral)\n\nTo see this, we need a tiny bit of machinery. Specifically, we need the concept of a Gaussian $\\nu$-noise and its corresponding integral.\n\n::: {#def-nu-noise}\n\n## Complex $\\nu$-noise\n\nA (complex) $\\nu$-noise^[This is not restricted to being Gaussian, but for all intents and porpoises it is.] is a random measure^[Countably additive set-valued function taking any value in $\\mathbb{C}$] $W(\\cdot)$ such that, for every^[$\\nu$-measurable] disjoint^[$A \\cap B = \\emptyset$] pair of sets $A, B$ satisfies the following properties\n\n1. $W(A)$ has mean zero and variance $\\nu(A)$,\n1. If $A$ and $B$ are disjoint then $W(A\\cup B) = W(A) + W(B)$\n1. If $A$ and $B$ are disjoint then $W(A)$ and $W(B)$ are uncorrelated^[If $W(A)$ is also Gaussian then this is the same as them being independent], ie $\\mathbb{E}(W(A) \\overline{W(B)}) = 0$.\n:::\n\nThis definition might not seem like much, but imagine a simple^[This is the technical term for this type of function because mathematicians weren't hugged enough as children.] piecewise constant function \n$$\nf(\\omega) = \\sum_{i=1}^{n} f_i 1_{A_i}(\\omega),\\quad g(\\omega) =  \\sum_{i=1}^{n} g_i 1_{A_i}(\\omega)\n$$\nwhere $f_i, g_i\\in \\mathbb{C}$ and the sets $A_i$ are pairwise disjoint and $\\bigcup_{i=1}^n A_i  = \\mathbb{R}^d$. Then we can define an integral with respect to the $\\nu$-noise as \n$$\n\\int_{\\mathbb{R}^d} f(\\omega)\\,dW(\\omega) = \\sum_{i=1}^n f_i W(A_i),\n$$\nwhich has mean $0$ and variance \n$$\n\\mathbb{E}\\left(\\int_{\\mathbb{R}^d} f(\\omega)\\,dW(\\omega)\\right)^2 = \\sum_{i=1}^n f_i \\nu(A_i) = \\int_{\\mathbb{R}^d}f(\\omega)\\,d\\nu(\\omega),\n$$\nwhere the last equality comes from the definition of an integral of a piecewise constant function.\n\nMoreover, we get the covariance\n\\begin{align*}\n\\mathbb{E}\\left(\\int_{\\mathbb{R}^d} f(\\omega)\\,dW(\\omega)\\overline{\\int_{\\mathbb{R}^d} g(\\omega)\\,dW(\\omega)}\\right)^2 &= \\sum_{i=1}^n \\sum_{j=1}^n f_ig_j \\nu(A_i \\cap A_j) \\\\\n&= \\sum_{i=1}^n f_i\\overline{g}_i \\nu(A_i) \\\\\n&= \\int_{\\mathbb{R}^d}f(\\omega)\\overline{g(\\omega)}\\,d\\nu(\\omega).\n\\end{align*}\n\nA nice thing is that while these piecewise constant functions are quite simple, we can approximate _any_^[for a particular value of \"any\"] function arbitrarily well by a simple function. This is the same fact we use to build ourselves ordinary^[for a particular value of \"ordinary\"] integrals.  \n\nIn particular, the brave and the bold among you might just say \"we can take limits here and _define_\" an integral with respect to the $\\nu$-noise this way. And, indeed, that works. You get that. for any $f\\in L^2(\\nu)$,\n\n$$\n\\mathbb{E}\\left(\\int_{\\mathbb{R}^d} f(\\omega)\\,d W(\\omega)\\right) = 0\n$$\nand, for any $f,g \\in L^2(\\nu)$,\n$$\n\\mathbb{E}\\left(\\int_{\\mathbb{R}^d} f(\\omega)\\,d W(\\omega)\\overline{\\int_{\\mathbb{R}^d} g(\\omega)\\,d W(\\omega)}\\right) = \\int_{\\mathbb{R}^d} f(\\omega)\\overline{g(\\omega)}\\,d \\nu(\\omega).\n$$\n\nIf we define\n$$\nu(s) = \\int_{\\mathbb{R}^d}e^{i\\omega^Ts}\\,dW(\\omega),\n$$\nthen it follows immediately that $u(s)$ is mean zero and has covariance function\n$$\n\\mathbb{E}(u(s)\\overline{u(s')}) = \\int_{\\mathbb{R}^d}e^{i\\omega^T(s - s')}\\, d\\nu(\\omega) = c(s-s').\n$$\nThat is $\\nu$ is the spectral measure associated with the correlation function. \n\nCombining this with Bochner's theorem, we have just proved^[Well enough for a statistician anyway. You can look it up the details but if you desperately need to formalise it, you build an isomorphism between $\\operatorname{span}\\{u(s), s \\in \\mathbb{R}^d\\}$ and $\\operatorname{span}\\{e^{i\\omega^Ts}, s \\in \\mathbb{R}^d\\}$ and use that to construct $W$. It's not _wildly_ difficult but it's also not actually interesting  except for mathturbatory reasons.] the spectral representation theorem for general^[Non-Gaussian!] (weakly) stationary^[On more spaces, the same construction still works. Just use whatever Fourier transform you have available.] random fields^[or stochastic processes].\n\n::: {#thm-spectral-rep}\n\n## Spectral representation theorem\n\nIf $\\nu$ is a finite, non-negative measure on $\\mathbb{R}^d$ and $W$ is a complex $\\nu$-noise, then the complex-valued process\n$$\nu(s) =\\int_{\\mathbb{R}^d}e^{i\\omega^Ts}\\,dW(\\omega)\n$$\nhas mean zero an covariance \n$$\nc(s,s') = \\int_{\\mathbb{R}^d}e^{i\\omega^T(s-s')}\\,d\\nu(\\omega)\n$$\nand is therefore weakly stationary. If $W(A) \\sim N(0, \\nu(A))$ then $u(s)$ is a Gaussian process.\n\nFurthermore, every mean-square continuous mean zero stationary Gaussian process with covariance function $c(s,s')= c(s-s')$ and corresponding spectral measure $\\nu$ has an associated $\\nu$-noise $W(\\cdot)$ such that\n$$\nu(s) =\\int_{\\mathbb{R}^d}e^{i\\omega^Ts}\\,dW(\\omega)\n$$\nholds in the mean-square sense for all $s \\in \\mathbb{R}^d$.\n\n$W(\\cdot)$ is called the _spectral process_ associated with $u(\\cdot)$. When it exists, the density of $\\nu$, denoted by $f(\\omega)$, is called the _spectral density_ or the _power spectrum_.\n:::\n\nAll throughout here I used complex numbers and complex Gaussian processes because, believe it or not, it makes things easier. But you will be pleased to know that $u(\\cdot)$ will be real-valued as long as the spectral density $f(\\omega)$ is symmetric around the origin. And it always is.\n\n\n### Using the spectrum to understand a stationary GP\n\nIt would've been a bit of an odd choice to spend all this time talking about spectral representations and never using them. So in this section, I'm going to cover the reason for the season: singularity or absolute continuity of Gaussian measures.\n\nThiis\n\nWhile the power spectrum\n\nThe spectral representation is a powerful tool for understanding (and, sometimes, computing with) stationary Gaussian processes. This is especially true when there is a s\n\n",
    "supporting": [
      "priors5_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}